 This project explores the complex field of synthetic speech detection, utilizing an advanced analysis framework that combines both short-term and long-term prediction traces.
 Leveraging cutting-edge deep learning methodologies such as Convolutional Neural Networks (CNN), WaveNet, an undisclosed model denoted as LSTM, and Recurrent Neural Networks (RNN), 
 our methodology endeavors to establish a robust mechanism for identifying synthetic speech across diverse contexts .Central to our approach is the extraction of a comprehensive array of features,
 encompassing both short-term attributes like Zero Crossing Rate and Spectral Control, and long-term characteristics such as Mel-Frequency Cepstral Coefficients (MFCC) and Chroma features. 
 Through meticulous data preprocessing, model training, and rigorous evaluation, our aim is to construct a system that exhibits high accuracy in discerning synthetic speech instances. 
 This initiative makes a substantial contribution to the evolution of speech processing techniques while offering potential applications in fraud detection, voice authentication, and content verification.
